<div align="center">

# ğŸ§® Linear Algebra Mastery Journey

<img src="https://readme-typing-svg.herokuapp.com?font=Fira+Code&size=28&duration=3000&pause=1000&color=FF6B6B&center=true&vCenter=true&width=800&lines=3Blue1Brown+Series+Implementation;Mathematical+Foundations+for+AI;Vectors%2C+Matrices+%26+Transformations;Building+Intuition+Through+Code" alt="Typing SVG" />

<img src="https://user-images.githubusercontent.com/74038190/225813708-98b745f2-7d22-48cf-9150-083f1b00d6c9.gif" width="400">

**Transforming abstract mathematics into visual understanding through hands-on implementation**

</div>

---

<div align="center">

## ğŸ¥ Video Library & Learning Resources

<img src="https://user-images.githubusercontent.com/74038190/212257468-1e9a91f1-b626-4baa-b15d-5c385b7ca7d0.gif" width="50">

</div>

### ğŸ“º 3Blue1Brown Original Series

<div align="center">

#### Chapter 1 Video
<a href="https://www.youtube.com/watch?v=fNk_zzaMoSs" target="_blank">
<img src="https://img.youtube.com/vi/fNk_zzaMoSs/maxresdefault.jpg" width="400" alt="Vectors, what even are they?"/>
</a>

**Vectors, what even are they? | Chapter 1, Essence of linear algebra**

#### Chapter 2 Video  
<a href="https://www.youtube.com/watch?v=k7RM-ot2NWY" target="_blank">
<img src="https://img.youtube.com/vi/k7RM-ot2NWY/maxresdefault.jpg" width="400" alt="Linear combinations, span, and basis vectors"/>
</a>

**Linear combinations, span, and basis vectors | Chapter 2, Essence of linear algebra**

#### Chapter 3 Video
<a href="https://www.youtube.com/watch?v=kYB8IZa5AuE" target="_blank">
<img src="https://img.youtube.com/vi/kYB8IZa5AuE/maxresdefault.jpg" width="400" alt="Linear transformations and matrices"/>
</a>

**Linear transformations and matrices | Chapter 3, Essence of linear algebra**

#### Chapter 4 Video
<a href="https://www.youtube.com/watch?v=XkY2DOUCWMU" target="_blank">
<img src="https://img.youtube.com/vi/XkY2DOUCWMU/maxresdefault.jpg" width="400" alt="Matrix multiplication as composition"/>
</a>

**Matrix multiplication as composition | Chapter 4, Essence of linear algebra**

</div>

### ğŸ¯ My Learning Process

```mermaid
graph TD
    A[ğŸ“º Watch 3Blue1Brown Video] --> B[ğŸ“ Take Detailed Notes]
    B --> C[ğŸ’» Implement in Python]
    C --> D[ğŸ¨ Create Visualizations]
    D --> E[ğŸ§  Write Key Insights]
    E --> F[ğŸ”— Connect to ML Applications]
    F --> G[âœ… Mark Complete]
    G --> H[ğŸ“Š Update Progress]
```

---

<div align="center">

## ğŸ¯ Learning Progress

<img src="https://user-images.githubusercontent.com/74038190/212284100-561aa473-3905-4a80-b561-0d28506553ee.gif" width="600">

</div>

### ğŸ“š 3Blue1Brown Essence of Linear Algebra Series

| Chapter | Topic | Status | Implementation | Notes |
|:-------:|:------|:------:|:-------------:|:-----:|
| 01 | **Vectors - What Even Are They?** | ![100%](https://progress-bar.dev/100/?scale=100&title=Complete&width=100&color=00ff00) | âœ… | [ğŸ“](./notes/chapter-01-vectors.md) [ğŸ¥](#chapter-1-video) |
| 02 | **Linear Combinations, Span & Basis** | ![100%](https://progress-bar.dev/100/?scale=100&title=Complete&width=100&color=00ff00) | âœ… | [ğŸ“](./notes/chapter-02-span.md) [ğŸ¥](#chapter-2-video) |
| 03 | **Linear Transformations & Matrices** | ![100%](https://progress-bar.dev/100/?scale=100&title=Complete&width=100&color=00ff00) | âœ… | [ğŸ“](./notes/chapter-03-transformations.md) [ğŸ¥](#chapter-3-video) |
| 04 | **Matrix Multiplication as Composition** | ![100%](https://progress-bar.dev/100/?scale=100&title=Complete&width=100&color=00ff00) | âœ… | [ğŸ“](./notes/chapter-04-multiplication.md) [ğŸ¥](#chapter-4-video) |
| 05 | **Three-Dimensional Linear Transformations** | ![100%](https://progress-bar.dev/100/?scale=100&title=Complete&width=100&color=00ff00) | âœ… | [ğŸ“](./notes/chapter-05-3d.md) [ğŸ¥](#chapter-5-video) |
| 06 | **The Determinant** | ![100%](https://progress-bar.dev/100/?scale=100&title=Complete&width=100&color=00ff00) | âœ… | [ğŸ“](./notes/chapter-06-determinant.md) [ğŸ¥](#chapter-6-video) |
| 07 | **Inverse Matrices, Column Space & Null Space** | ![100%](https://progress-bar.dev/100/?scale=100&title=Complete&width=100&color=00ff00) | âœ… | [ğŸ“](./notes/chapter-07-inverse.md) [ğŸ¥](#chapter-7-video) |
| 08 | **Nonsquare Matrices as Transformations** | ![50%](https://progress-bar.dev/50/?scale=100&title=In%20Progress&width=100&color=ff6b6b) | ğŸ”„ | [ğŸ“](./notes/chapter-08-nonsquare.md) [ğŸ¥](#chapter-8-video) |
| 09 | **Dot Products and Duality** | ![0%](https://progress-bar.dev/0/?scale=100&title=Pending&width=100&color=gray) | â³ | â³ |
| 10 | **Cross Products** | ![0%](https://progress-bar.dev/0/?scale=100&title=Pending&width=100&color=gray) | â³ | â³ |
| 11 | **Cross Products in the Light of Linear Transformations** | ![0%](https://progress-bar.dev/0/?scale=100&title=Pending&width=100&color=gray) | â³ | â³ |
| 12 | **Cramer's Rule** | ![0%](https://progress-bar.dev/0/?scale=100&title=Pending&width=100&color=gray) | â³ | â³ |
| 13 | **Change of Basis** | ![0%](https://progress-bar.dev/0/?scale=100&title=Pending&width=100&color=gray) | â³ | â³ |
| 14 | **Eigenvectors and Eigenvalues** | ![0%](https://progress-bar.dev/0/?scale=100&title=Pending&width=100&color=gray) | â³ | â³ |
| 15 | **Abstract Vector Spaces** | ![0%](https://progress-bar.dev/0/?scale=100&title=Pending&width=100&color=gray) | â³ | â³ |

<div align="center">

**Overall Progress**: ![50%](https://progress-bar.dev/50/?scale=100&title=Mastery&width=200&color=gradient)

</div>

---

<div align="center">

## ğŸ—‚ï¸ Repository Structure

<img src="https://user-images.githubusercontent.com/74038190/212257467-871d32b7-e401-42e8-a166-fcfd7baa4c6b.gif" width="50">

</div>

```
ğŸ“¦ linear-algebra-learning/
â”œâ”€â”€ ğŸ“‹ README.md                    # This overview
â”œâ”€â”€ ğŸ“ notes/                       # Chapter-by-chapter notes
â”‚   â”œâ”€â”€ ğŸ“„ chapter-01-vectors.md
â”‚   â”œâ”€â”€ ğŸ“„ chapter-02-span.md
â”‚   â””â”€â”€ ğŸ“„ ...
â”œâ”€â”€ ğŸ’» implementations/             # Python code implementations
â”‚   â”œâ”€â”€ ğŸ vector_operations.py
â”‚   â”œâ”€â”€ ğŸ matrix_transformations.py
â”‚   â”œâ”€â”€ ğŸ visualizations.py
â”‚   â””â”€â”€ ğŸ ...
â”œâ”€â”€ ğŸ¨ visualizations/              # Generated plots and animations
â”‚   â”œâ”€â”€ ğŸ–¼ï¸ vector_addition.png
â”‚   â”œâ”€â”€ ğŸ¬ linear_transformation.gif
â”‚   â””â”€â”€ ğŸ–¼ï¸ ...
â”œâ”€â”€ ğŸ§ª exercises/                   # Practice problems & solutions
â”‚   â”œâ”€â”€ ğŸ“ practice_problems.md
â”‚   â””â”€â”€ ğŸ solutions.py
â””â”€â”€ ğŸ’¡ insights/                    # Key learnings & aha moments
    â”œâ”€â”€ ğŸ“„ breakthrough_moments.md
    â””â”€â”€ ğŸ“„ connections_to_ml.md
```

---

<div align="center">

## ğŸ¨ Current Focus: Chapter 8 - Nonsquare Matrices

<img src="https://user-images.githubusercontent.com/74038190/212284087-bbe7e430-757e-4901-90bf-4cd2ce3e1852.gif" width="50">

</div>

### ğŸ”¥ What I'm Working On Right Now

```python
# ğŸš€ Latest Implementation: Nonsquare Matrix Transformations
import numpy as np
import matplotlib.pyplot as plt

class LinearTransformation:
    def __init__(self, matrix):
        self.matrix = np.array(matrix)
        self.input_dim = matrix.shape[1]
        self.output_dim = matrix.shape[0]
    
    def transform(self, vector):
        """Apply transformation to vector"""
        return self.matrix @ vector
    
    def visualize_transformation(self, input_space, output_space):
        """Visualize how transformation maps between spaces"""
        # From 2D to 3D or 3D to 2D - mind-blowing! ğŸ¤¯
        pass

# Understanding dimension changes through linear algebra! 
nonsquare = LinearTransformation([[1, 2], [3, 4], [5, 6]])  # 2D â†’ 3D
result = nonsquare.transform([1, 1])  # Magic dimensionality! âœ¨
```

### ğŸ¯ Chapter 8 Objectives
- [x] **Understand nonsquare matrices conceptually** ğŸ“
- [x] **Implement 2Dâ†’3D and 3Dâ†’2D transformations** â•
- [ ] **Visualize dimension changes** ğŸ¨
- [ ] **Connect to data compression & expansion** ğŸ“Š
- [ ] **Link to neural network layers** ğŸ¤–

---

<div align="center">

## ğŸ§  Key Insights & Breakthrough Moments

<img src="https://user-images.githubusercontent.com/74038190/212257454-16e3712e-945a-4ca2-b238-408ad0bf87e6.gif" width="50">

</div>

### ğŸ’¡ Latest "Aha!" Moments

> **ğŸ”¥ Nonsquare matrices change dimensions!**  
> Just realized that when we multiply a 3Ã—2 matrix by a 2D vector, we get a 3D vector! This is how neural networks transform data between layers! ğŸ¤¯

> **âš¡ Matrix multiplication is function composition**  
> Each matrix is like a function that transforms space. When we multiply matrices, we're composing transformations. This completely changed how I see deep learning architectures!

> **ğŸš€ Determinants measure "scaling factor"**  
> The determinant tells us how much a transformation scales areas/volumes. Negative determinants flip orientation. This is crucial for understanding invertibility!

### ğŸ”— Connections to Machine Learning

```mermaid
graph LR
    A[Vectors] --> B[Data Points]
    A --> C[Feature Vectors]
    A --> D[Neural Network Weights]
    
    E[Linear Transformations] --> F[Model Parameters]
    E --> G[Data Preprocessing]
    E --> H[Dimensionality Reduction]
    
    I[Eigenvalues/Eigenvectors] --> J[PCA]
    I --> K[Stability Analysis]
    I --> L[Spectral Clustering]
```

---

<div align="center">

## ğŸ› ï¸ Tools & Technologies

![Python](https://img.shields.io/badge/python-3670A0?style=for-the-badge&logo=python&logoColor=ffdd54)
![NumPy](https://img.shields.io/badge/numpy-%23013243.svg?style=for-the-badge&logo=numpy&logoColor=white)
![Matplotlib](https://img.shields.io/badge/Matplotlib-%23ffffff.svg?style=for-the-badge&logo=Matplotlib&logoColor=black)
![Jupyter Notebook](https://img.shields.io/badge/jupyter-%23FA0F00.svg?style=for-the-badge&logo=jupyter&logoColor=white)

</div>

---

<div align="center">

## ğŸ“ˆ Learning Stats

<img src="https://github-readme-stats.vercel.app/api/pin/?username=pyritomath&repo=linear-algebra-learning&theme=tokyonight&hide_border=true&bg_color=1A1B27&title_color=70A5FD&icon_color=bf91f3&text_color=38BDF8" />

### ğŸ¯ Goals
- **Complete 3Blue1Brown series**: 15 chapters
- **Build 50+ implementations**: Hands-on coding
- **Create 20+ visualizations**: Make math beautiful
- **Write comprehensive notes**: Knowledge retention
- **Connect to 10+ ML applications**: Practical relevance

</div>

---

<div align="center">

## ğŸš€ Next Steps

<img src="https://user-images.githubusercontent.com/74038190/212281775-b468df30-4edc-4bf8-a4ee-f52e1aaddc86.gif" width="80">

### ğŸ“… This Week
- [ ] Complete Chapter 1 implementation
- [ ] Create vector addition visualization
- [ ] Start Chapter 2: Linear combinations
- [ ] Write detailed notes on span and basis

### ğŸ¯ This Month
- [ ] Master first 5 chapters
- [ ] Build comprehensive visualization library
- [ ] Create interactive demos
- [ ] Start connecting concepts to ML algorithms

</div>

---

<div align="center">

### ğŸ’­ Learning Philosophy

*"Mathematics is not about numbers, equations, computations, or algorithms: it is about understanding."* - William Paul Thurston

**Every concept implemented â€¢ Every visualization created â€¢ Every connection made**

<img src="https://capsule-render.vercel.app/api?type=waving&color=gradient&height=80&section=footer&width=100%"/>

</div>
