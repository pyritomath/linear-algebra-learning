<div align="center">

# 🧮 Linear Algebra Mastery Journey

<img src="https://readme-typing-svg.herokuapp.com?font=Fira+Code&size=28&duration=3000&pause=1000&color=FF6B6B&center=true&vCenter=true&width=800&lines=3Blue1Brown+Series+Implementation;Mathematical+Foundations+for+AI;Vectors%2C+Matrices+%26+Transformations;Building+Intuition+Through+Code" alt="Typing SVG" />

<img src="https://user-images.githubusercontent.com/74038190/212741999-016fddbd-617a-4448-8042-0ecf907aea25.gif" width="500">

**Transforming abstract mathematics into visual understanding through hands-on implementation**

</div>

---

<div align="center">

## 🎥 Video Library & Learning Resources

<img src="https://user-images.githubusercontent.com/74038190/229223263-cf2e4b07-2615-4f87-9c38-e37600f8381a.gif" width="50">

</div>

### 📺 3Blue1Brown Original Series

<div align="center">

#### Chapter 1 Video
<a href="https://www.youtube.com/watch?v=fNk_zzaMoSs" target="_blank">
<img src="https://img.youtube.com/vi/fNk_zzaMoSs/maxresdefault.jpg" width="400" alt="Vectors, what even are they?"/>
</a>

**Vectors, what even are they? | Chapter 1, Essence of linear algebra**

#### Chapter 2 Video  
<a href="https://www.youtube.com/watch?v=k7RM-ot2NWY" target="_blank">
<img src="https://img.youtube.com/vi/k7RM-ot2NWY/maxresdefault.jpg" width="400" alt="Linear combinations, span, and basis vectors"/>
</a>

**Linear combinations, span, and basis vectors | Chapter 2, Essence of linear algebra**

#### Chapter 3 Video
<a href="https://www.youtube.com/watch?v=kYB8IZa5AuE" target="_blank">
<img src="https://img.youtube.com/vi/kYB8IZa5AuE/maxresdefault.jpg" width="400" alt="Linear transformations and matrices"/>
</a>

**Linear transformations and matrices | Chapter 3, Essence of linear algebra**

#### Chapter 4 Video
<a href="https://www.youtube.com/watch?v=XkY2DOUCWMU" target="_blank">
<img src="https://img.youtube.com/vi/XkY2DOUCWMU/maxresdefault.jpg" width="400" alt="Matrix multiplication as composition"/>
</a>

**Matrix multiplication as composition | Chapter 4, Essence of linear algebra**

</div>

### 🎯 My Learning Process

```mermaid
graph TD
    A[📺 Watch 3Blue1Brown Video] --> B[📝 Take Detailed Notes]
    B --> C[💻 Implement in Python]
    C --> D[🎨 Create Visualizations]
    D --> E[🧠 Write Key Insights]
    E --> F[🔗 Connect to ML Applications]
    F --> G[✅ Mark Complete]
    G --> H[📊 Update Progress]
```

---

<div align="center">

## 🎯 Learning Progress

<img src="https://user-images.githubusercontent.com/74038190/212741999-016fddbd-617a-4448-8042-0ecf907aea25.gif" width="700">

</div>

### 📚 3Blue1Brown Essence of Linear Algebra Series

| Chapter | Topic | Status | Implementation | Notes |
|:-------:|:------|:------:|:-------------:|:-----:|
| 01 | **Vectors - What Even Are They?** | ![100%](https://progress-bar.dev/100/?scale=100&title=Complete&width=100&color=00ff00) | ✅ | [📝](./notes/chapter-01-vectors.md) [🎥](#chapter-1-video) |
| 02 | **Linear Combinations, Span & Basis** | ![100%](https://progress-bar.dev/100/?scale=100&title=Complete&width=100&color=00ff00) | ✅ | [📝](./notes/chapter-02-span.md) [🎥](#chapter-2-video) |
| 03 | **Linear Transformations & Matrices** | ![100%](https://progress-bar.dev/100/?scale=100&title=Complete&width=100&color=00ff00) | ✅ | [📝](./notes/chapter-03-transformations.md) [🎥](#chapter-3-video) |
| 04 | **Matrix Multiplication as Composition** | ![100%](https://progress-bar.dev/100/?scale=100&title=Complete&width=100&color=00ff00) | ✅ | [📝](./notes/chapter-04-multiplication.md) [🎥](#chapter-4-video) |
| 05 | **Three-Dimensional Linear Transformations** | ![100%](https://progress-bar.dev/100/?scale=100&title=Complete&width=100&color=00ff00) | ✅ | [📝](./notes/chapter-05-3d.md) [🎥](#chapter-5-video) |
| 06 | **The Determinant** | ![100%](https://progress-bar.dev/100/?scale=100&title=Complete&width=100&color=00ff00) | ✅ | [📝](./notes/chapter-06-determinant.md) [🎥](#chapter-6-video) |
| 07 | **Inverse Matrices, Column Space & Null Space** | ![100%](https://progress-bar.dev/100/?scale=100&title=Complete&width=100&color=00ff00) | ✅ | [📝](./notes/chapter-07-inverse.md) [🎥](#chapter-7-video) |
| 08 | **Nonsquare Matrices as Transformations** | ![50%](https://progress-bar.dev/50/?scale=100&title=In%20Progress&width=100&color=ff6b6b) | 🔄 | [📝](./notes/chapter-08-nonsquare.md) [🎥](#chapter-8-video) |
| 09 | **Dot Products and Duality** | ![0%](https://progress-bar.dev/0/?scale=100&title=Pending&width=100&color=gray) | ⏳ | ⏳ |
| 10 | **Cross Products** | ![0%](https://progress-bar.dev/0/?scale=100&title=Pending&width=100&color=gray) | ⏳ | ⏳ |
| 11 | **Cross Products in the Light of Linear Transformations** | ![0%](https://progress-bar.dev/0/?scale=100&title=Pending&width=100&color=gray) | ⏳ | ⏳ |
| 12 | **Cramer's Rule** | ![0%](https://progress-bar.dev/0/?scale=100&title=Pending&width=100&color=gray) | ⏳ | ⏳ |
| 13 | **Change of Basis** | ![0%](https://progress-bar.dev/0/?scale=100&title=Pending&width=100&color=gray) | ⏳ | ⏳ |
| 14 | **Eigenvectors and Eigenvalues** | ![0%](https://progress-bar.dev/0/?scale=100&title=Pending&width=100&color=gray) | ⏳ | ⏳ |
| 15 | **Abstract Vector Spaces** | ![0%](https://progress-bar.dev/0/?scale=100&title=Pending&width=100&color=gray) | ⏳ | ⏳ |

<div align="center">

**Overall Progress**: ![50%](https://progress-bar.dev/50/?scale=100&title=Mastery&width=200&color=gradient)

</div>

---

<div align="center">

## 🗂️ Repository Structure

<img src="https://user-images.githubusercontent.com/74038190/229223263-cf2e4b07-2615-4f87-9c38-e37600f8381a.gif" width="50">

</div>

```
📦 linear-algebra-learning/
├── 📋 README.md                    # This overview
├── 📝 notes/                       # Chapter-by-chapter notes
│   ├── 📄 chapter-01-vectors.md
│   ├── 📄 chapter-02-span.md
│   └── 📄 ...
├── 💻 implementations/             # Python code implementations
│   ├── 🐍 vector_operations.py
│   ├── 🐍 matrix_transformations.py
│   ├── 🐍 visualizations.py
│   └── 🐍 ...
├── 🎨 visualizations/              # Generated plots and animations
│   ├── 🖼️ vector_addition.png
│   ├── 🎬 linear_transformation.gif
│   └── 🖼️ ...
├── 🧪 exercises/                   # Practice problems & solutions
│   ├── 📝 practice_problems.md
│   └── 🐍 solutions.py
└── 💡 insights/                    # Key learnings & aha moments
    ├── 📄 breakthrough_moments.md
    └── 📄 connections_to_ml.md
```

---

<div align="center">

## 🎨 Current Focus: Chapter 8 - Nonsquare Matrices

<img src="https://user-images.githubusercontent.com/74038190/216122041-518ac897-8d92-4c6b-9b3f-ca01dcaf38ee.gif" width="50">

</div>

### 🔥 What I'm Working On Right Now

```python
# 🚀 Latest Implementation: Nonsquare Matrix Transformations
import numpy as np
import matplotlib.pyplot as plt

class LinearTransformation:
    def __init__(self, matrix):
        self.matrix = np.array(matrix)
        self.input_dim = matrix.shape[1]
        self.output_dim = matrix.shape[0]
    
    def transform(self, vector):
        """Apply transformation to vector"""
        return self.matrix @ vector
    
    def visualize_transformation(self, input_space, output_space):
        """Visualize how transformation maps between spaces"""
        # From 2D to 3D or 3D to 2D - mind-blowing! 🤯
        pass

# Understanding dimension changes through linear algebra! 
nonsquare = LinearTransformation([[1, 2], [3, 4], [5, 6]])  # 2D → 3D
result = nonsquare.transform([1, 1])  # Magic dimensionality! ✨
```

### 🎯 Chapter 8 Objectives
- [x] **Understand nonsquare matrices conceptually** 📐
- [x] **Implement 2D→3D and 3D→2D transformations** ➕
- [ ] **Visualize dimension changes** 🎨
- [ ] **Connect to data compression & expansion** 📊
- [ ] **Link to neural network layers** 🤖

---

<div align="center">

## 🧠 Key Insights & Breakthrough Moments

<img src="https://user-images.githubusercontent.com/74038190/216122041-518ac897-8d92-4c6b-9b3f-ca01dcaf38ee.gif" width="50">

</div>

### 💡 Latest "Aha!" Moments

> **🔥 Nonsquare matrices change dimensions!**  
> Just realized that when we multiply a 3×2 matrix by a 2D vector, we get a 3D vector! This is how neural networks transform data between layers! 🤯

> **⚡ Matrix multiplication is function composition**  
> Each matrix is like a function that transforms space. When we multiply matrices, we're composing transformations. This completely changed how I see deep learning architectures!

> **🚀 Determinants measure "scaling factor"**  
> The determinant tells us how much a transformation scales areas/volumes. Negative determinants flip orientation. This is crucial for understanding invertibility!

### 🔗 Connections to Machine Learning

```mermaid
graph LR
    A[Vectors] --> B[Data Points]
    A --> C[Feature Vectors]
    A --> D[Neural Network Weights]
    
    E[Linear Transformations] --> F[Model Parameters]
    E --> G[Data Preprocessing]
    E --> H[Dimensionality Reduction]
    
    I[Eigenvalues/Eigenvectors] --> J[PCA]
    I --> K[Stability Analysis]
    I --> L[Spectral Clustering]
```

---

<div align="center">

## 🛠️ Tools & Technologies

![Python](https://img.shields.io/badge/python-3670A0?style=for-the-badge&logo=python&logoColor=ffdd54)
![NumPy](https://img.shields.io/badge/numpy-%23013243.svg?style=for-the-badge&logo=numpy&logoColor=white)
![Matplotlib](https://img.shields.io/badge/Matplotlib-%23ffffff.svg?style=for-the-badge&logo=Matplotlib&logoColor=black)
![Jupyter Notebook](https://img.shields.io/badge/jupyter-%23FA0F00.svg?style=for-the-badge&logo=jupyter&logoColor=white)

</div>

---

<div align="center">

## 📈 Learning Stats

<img src="https://github-readme-stats.vercel.app/api/pin/?username=pyritomath&repo=linear-algebra-learning&theme=tokyonight&hide_border=true&bg_color=1A1B27&title_color=70A5FD&icon_color=bf91f3&text_color=38BDF8" />

### 🎯 Goals
- **Complete 3Blue1Brown series**: 15 chapters
- **Build 50+ implementations**: Hands-on coding
- **Create 20+ visualizations**: Make math beautiful
- **Write comprehensive notes**: Knowledge retention
- **Connect to 10+ ML applications**: Practical relevance

</div>

---

<div align="center">

## 🚀 Next Steps

<img src="https://user-images.githubusercontent.com/74038190/216644497-1951db19-8f3d-4e44-ac08-8e9d7e0d94a7.gif" width="80">

### 📅 This Week
- [ ] Complete Chapter 1 implementation
- [ ] Create vector addition visualization
- [ ] Start Chapter 2: Linear combinations
- [ ] Write detailed notes on span and basis

### 🎯 This Month
- [ ] Master first 5 chapters
- [ ] Build comprehensive visualization library
- [ ] Create interactive demos
- [ ] Start connecting concepts to ML algorithms

</div>

---

<div align="center">

### 💭 Learning Philosophy

*"Mathematics is not about numbers, equations, computations, or algorithms: it is about understanding."* - William Paul Thurston

**Every concept implemented • Every visualization created • Every connection made**

<img src="https://capsule-render.vercel.app/api?type=waving&color=gradient&height=80&section=footer&width=100%"/>

</div>
